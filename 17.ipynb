{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def head(X: list, n = 5) -> list:\n",
    "    \"\"\"\n",
    "    return `n` (default is 5) first rows of a 2D list\n",
    "    ### Parameters\n",
    "    `X` : The 2D list\n",
    "    `n` : number of first rows\n",
    "    ### Example\n",
    "    ```python\n",
    "    >>> X = [[1,2], [3,4], [5,6]]\n",
    "    >>> print(head(X))\n",
    "    [[1,2],\n",
    "     [3,4],\n",
    "     [5,6]]\n",
    "    >>> print(head(X,2))\n",
    "    [[1,2],\n",
    "     [3,4]]\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return X[:n]\n",
    "\n",
    "def tail(X: list, n = 5) -> list:\n",
    "    \"\"\"\n",
    "    return `n` (default is 5) last rows of a 2D list\n",
    "    ### Parameters\n",
    "    `X` : The 2D list\n",
    "    `n` : number of last rows\n",
    "    ### Example\n",
    "    ```python\n",
    "    >>> X = [[1,2], [3,4], [5,6]]\n",
    "    >>> print(tail(X))\n",
    "    [[1,2],\n",
    "     [3,4],\n",
    "     [5,6]]\n",
    "    >>> print(tail(X,2))\n",
    "    [[3,4],\n",
    "     [5,6]]\n",
    "    ```\n",
    "    \"\"\"\n",
    "    return X[(-n):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.fetch_california_housing()\n",
    "X = boston.data\n",
    "y = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(13,input_dim=8,activation=\"relu\"))\n",
    "# 13 neurons and input dim = 13, activation function is ReLU\n",
    "model.add(Dense(1))\n",
    "#output layer\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "# which algorithm is used for backpropagation is defined by the optimizer which is adam here, not the usual gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.9776\n",
      "Epoch 2/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.4768\n",
      "Epoch 3/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.4274\n",
      "Epoch 4/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.4068\n",
      "Epoch 5/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3950\n",
      "Epoch 6/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3836\n",
      "Epoch 7/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3794\n",
      "Epoch 8/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3721\n",
      "Epoch 9/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3752\n",
      "Epoch 10/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3690\n",
      "Epoch 11/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3625\n",
      "Epoch 12/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3585\n",
      "Epoch 13/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3547\n",
      "Epoch 14/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3589\n",
      "Epoch 15/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3518\n",
      "Epoch 16/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3521\n",
      "Epoch 17/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3484\n",
      "Epoch 18/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3466\n",
      "Epoch 19/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3421\n",
      "Epoch 20/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3540\n",
      "Epoch 21/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3376\n",
      "Epoch 22/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3361\n",
      "Epoch 23/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3358\n",
      "Epoch 24/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3402\n",
      "Epoch 25/150\n",
      "1652/1652 [==============================] - 9s 5ms/step - loss: 0.3375\n",
      "Epoch 26/150\n",
      "1652/1652 [==============================] - 9s 5ms/step - loss: 0.3301\n",
      "Epoch 27/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3294\n",
      "Epoch 28/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3331\n",
      "Epoch 29/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3259\n",
      "Epoch 30/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3267\n",
      "Epoch 31/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3273\n",
      "Epoch 32/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3208\n",
      "Epoch 33/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3267\n",
      "Epoch 34/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3220\n",
      "Epoch 35/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3207\n",
      "Epoch 36/150\n",
      "1652/1652 [==============================] - 9s 6ms/step - loss: 0.3204\n",
      "Epoch 37/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3233\n",
      "Epoch 38/150\n",
      "1652/1652 [==============================] - 12s 7ms/step - loss: 0.3186\n",
      "Epoch 39/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3197\n",
      "Epoch 40/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3170\n",
      "Epoch 41/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3166\n",
      "Epoch 42/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3178\n",
      "Epoch 43/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3183\n",
      "Epoch 44/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3154\n",
      "Epoch 45/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3191\n",
      "Epoch 46/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3119\n",
      "Epoch 47/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3153\n",
      "Epoch 48/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3135\n",
      "Epoch 49/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3130\n",
      "Epoch 50/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3118\n",
      "Epoch 51/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3156\n",
      "Epoch 52/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3124\n",
      "Epoch 53/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3082\n",
      "Epoch 54/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3139\n",
      "Epoch 55/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3098\n",
      "Epoch 56/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3116\n",
      "Epoch 57/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3076\n",
      "Epoch 58/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3125\n",
      "Epoch 59/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3086\n",
      "Epoch 60/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3073\n",
      "Epoch 61/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3107\n",
      "Epoch 62/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3084\n",
      "Epoch 63/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3136\n",
      "Epoch 64/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3062\n",
      "Epoch 65/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3072\n",
      "Epoch 66/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3090\n",
      "Epoch 67/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3092\n",
      "Epoch 68/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3080\n",
      "Epoch 69/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3100\n",
      "Epoch 70/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3108\n",
      "Epoch 71/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3092\n",
      "Epoch 72/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3066\n",
      "Epoch 73/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3063\n",
      "Epoch 74/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3039\n",
      "Epoch 75/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3079\n",
      "Epoch 76/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3085\n",
      "Epoch 77/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3101\n",
      "Epoch 78/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3077\n",
      "Epoch 79/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3057\n",
      "Epoch 80/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3021\n",
      "Epoch 81/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3085\n",
      "Epoch 82/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3034\n",
      "Epoch 83/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3029\n",
      "Epoch 84/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3019\n",
      "Epoch 85/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3051\n",
      "Epoch 86/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3036\n",
      "Epoch 87/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3085\n",
      "Epoch 88/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3049\n",
      "Epoch 89/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3007\n",
      "Epoch 90/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3061\n",
      "Epoch 91/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3038\n",
      "Epoch 92/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3012\n",
      "Epoch 93/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3013\n",
      "Epoch 94/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.2999\n",
      "Epoch 95/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3031\n",
      "Epoch 96/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3032\n",
      "Epoch 97/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3081\n",
      "Epoch 98/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3021\n",
      "Epoch 99/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3017\n",
      "Epoch 100/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3007\n",
      "Epoch 101/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.2988\n",
      "Epoch 102/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3076\n",
      "Epoch 103/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3043\n",
      "Epoch 104/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.2989\n",
      "Epoch 105/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3056\n",
      "Epoch 106/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3004\n",
      "Epoch 107/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3057\n",
      "Epoch 108/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3016\n",
      "Epoch 109/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3023\n",
      "Epoch 110/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3045\n",
      "Epoch 111/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2993\n",
      "Epoch 112/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3036\n",
      "Epoch 113/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2970\n",
      "Epoch 114/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.2978\n",
      "Epoch 115/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3031\n",
      "Epoch 116/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.2975\n",
      "Epoch 117/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.2974\n",
      "Epoch 118/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3122\n",
      "Epoch 119/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3013\n",
      "Epoch 120/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3001\n",
      "Epoch 121/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2972\n",
      "Epoch 122/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3001\n",
      "Epoch 123/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3007\n",
      "Epoch 124/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.3075\n",
      "Epoch 125/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2974\n",
      "Epoch 126/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.2991\n",
      "Epoch 127/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.2981\n",
      "Epoch 128/150\n",
      "1652/1652 [==============================] - 9s 5ms/step - loss: 0.3044\n",
      "Epoch 129/150\n",
      "1652/1652 [==============================] - 9s 6ms/step - loss: 0.2979\n",
      "Epoch 130/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.2959\n",
      "Epoch 131/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.2990\n",
      "Epoch 132/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2971\n",
      "Epoch 133/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2968\n",
      "Epoch 134/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.3003\n",
      "Epoch 135/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.2987\n",
      "Epoch 136/150\n",
      "1652/1652 [==============================] - 6s 3ms/step - loss: 0.2943\n",
      "Epoch 137/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2970\n",
      "Epoch 138/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2964\n",
      "Epoch 139/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.3024\n",
      "Epoch 140/150\n",
      "1652/1652 [==============================] - 8s 5ms/step - loss: 0.2975\n",
      "Epoch 141/150\n",
      "1652/1652 [==============================] - 11s 7ms/step - loss: 0.2976\n",
      "Epoch 142/150\n",
      "1652/1652 [==============================] - 11s 6ms/step - loss: 0.2955\n",
      "Epoch 143/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.2946\n",
      "Epoch 144/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2931\n",
      "Epoch 145/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.3087\n",
      "Epoch 146/150\n",
      "1652/1652 [==============================] - 7s 4ms/step - loss: 0.2913\n",
      "Epoch 147/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2928\n",
      "Epoch 148/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2952\n",
      "Epoch 149/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2985\n",
      "Epoch 150/150\n",
      "1652/1652 [==============================] - 6s 4ms/step - loss: 0.2917\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xtrain, ytrain, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.2975811 , 2.808711  , 0.8787091 , ..., 1.2998356 , 0.82192177,\n",
       "       1.7602472 ], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = model.predict(Xtest)\n",
    "ypred = ypred[:,0]\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Error is 18.530023602314277 %\n"
     ]
    }
   ],
   "source": [
    "error = np.sum(np.abs(ytest-ypred))/np.sum(np.abs(ytest))*100\n",
    "print('Prediction Error is',error,'%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
